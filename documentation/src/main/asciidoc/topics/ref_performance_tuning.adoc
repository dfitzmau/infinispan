[id='performance-tuning_{context}']
= Performance tuning guidelines

This topic gives you information and tweaks for tuning {brandname} performance.

== Java Virtual Machine settings

Java Virtual Machine tuning can be divided into sections like memory or GC.
Below is a list of helpful configuration parameters and a guide how to adjust them.

[discrete]
=== Memory settings

Adjusting memory size is one of the most crucial step in {brandname} tuning. The most commonly used JVM flags are:

* `-Xms` - Defines the minimum heap size allowed.
* `-Xmx` - Defines the maximum heap size allowed.
* `-Xmn` - Defines the minimum and maximum value for the young generation.
* `-XX:NewRatio` - Define the ratio between young and old generations. Should not be used if -Xmn is enabled.

Using `Xms` equal to `Xmx` will prevent JVM from dynamically sizing memory and might decrease GC pauses caused by resizing.
It is a good practice to specify `Xmn` parameter. This guaranteed proper behavior during load peak (in such case {brandname} generates lots of small, short living objects).

[discrete]
=== Garbage collection

The main goal is to minimize the amount of time when JVM is paused. Having said that, CMS is a suggested GC for {brandname} applications.

The most frequently used JVM flags are:

* `-XX:MaxGCPauseMillis` - Sets a target for the maximum GC pause time. Should be tuned to meet the SLA.
* `-XX:+UseConcMarkSweepGC` - Enables usage of the CMS collector.
* `-XX:+CMSClassUnloadingEnabled` - Allows class unloading when the CMS collector is enabled.
* `-XX:+UseParNewGC` - Utilize a parallel collector for the young generation. This parameter minimizes pausing by using multiple collection threads in parallel.
* `-XX:+DisableExplicitGC` - Prevent explicit garbage collections.
* `-XX:+UseG1GC` - Turn on G1 Garbage Collector.

[discrete]
=== Other settings

There are two additional parameters which are suggested to be used:

* `-server` - Enables server mode for the JVM.
* `-XX:+ UseLargePages` - Instructs the JVM to allocate memory in Large Pages. These pages must be configured at the OS level for this parameter to function successfully.

[discrete]
=== Example configuration

In most of the cases we suggest using CMS. However when using the latest JVM, G1 might perform slightly better.

.32GB JVM
----
-server
-Xmx32G
-Xms32G
-Xmn8G
-XX:+UseLargePages
-XX:+UseConcMarkSweepGC
-XX:+UseParNewGC
-XX:+DisableExplicitGC
----

.32GB JVM with G1 Garbage Collector
----
-server
-Xmx32G
-Xms32G
-Xmn8G
-XX:+UseG1GC
----

== Network configuration

{brandname} uses TCP/IP for sending packets over the network (for both cluster communication when using TCP stack or when communication with Hot Rod clients)

In order to achieve the best results, it is recommended to increase TCP send and receive window size (refer to you OS manual for instructions).
The recommended values are:

* send window size - 640 KB
* receive window size - 25 MB

== Thread pool settings

A thread pool manages threads by assigning them concurrent tasks.
Additionally, a thread pool can improve system performance by using any idle thread instead of creating threads.

You can configure your `threading` subsystem, so that you can better manage thread pools and their resources. 

[NOTE]
====
Consider only configuring the `threading` subsystem when necessary, such as configuring it to define a behavior that meet your needs. 
====

The following table outlines common `threading` subsystem components that you can configure:

[cols="1,1,3"]
|===
| Component  | Attribute type |Description

|`blocking-bounded-queue-thread-pool`|string and integer | A thread pool executor that can run blocking operations. 
Executor checks that the number of running threads does not exceed the core size; otherwise, the executor creates new threads. 
The thread pool uses a best effort approach to maintain a low number of running threads, such as reusing idle threads where possible.
This behavior differs from the JRE's `ThreadPoolExecutor` that creates new threads for each generated request until core size limitations apply.
Attributes include,`core-threads`, `keepalive-time`, `queue-length`, `thread-factory`, `max-threads`, and `name`.

|`cached-thread-pool` |string| A thread pool executor that creates new threads when an idle thread cannot be used with no bounds. The `name` and `thread-factory` attributes are mandatory.

|`non-blocking-bounded-queue-thread-pool` | string and integer a| A thread pool executor that can run non-blocking operations. 
Executor creates new threads when the number of running threads is less that the core size. 
Idle threads are placed in a queue.

Includes similar attributes to the blocking-bounded-queue-thread-pool` component.

|`scheduled-thread-pool`|string|A thread pool executor that creates a single-threaded executor that schedules commands to run at a specific time.
The `name` and `thread-factory` attributes are mandatory. 

|`thread-factory` |string| Specifies metadata for your threads pools. 
The `name` attribute and the `thread-name-pattern` attributes are mandatory. 
Optional attributes include `group-name` and `priority`.
|===

Your {brandname} configuration contains a cache container security configuration that applies default settings to thread pools.

The following table outlines common thread pool properties and their default thread property settings that exist in the cache container security configuration. 
Each thread pool property contains a `DEFAULT_THREAD_PRIORITY` thread property that default to `NORM_PRIORITY`.   

[cols="1,2,3"]
|===
| Property | `DEFAULT_THREAD_COUNT` / `DEFAULT_QUEUE_SIZE` | Description

|`ASYNC_NOTIFICATION_EXECUTOR` |`1` / `1000`| Used by asynchronous listeners that your {brandname} server registers in embedded mode.
Configuring this property is discouraged. 
The default setting of one thread ensures that {brandname} invokes asynchronous listeners by order of occurrence.
Increasing the thread pool size might cause threads to handle events in a different order than the events were generated.
Increasing the property's value from `1` might cause your {brandname} server to randomly create mixed types of listener events on different threads.

|`BLOCKING_EXECUTOR` | `150` / `5000`  |  Used by your {brandname} server to handle blocking operations.
An example of a blocking operation includes a cache store that calls external sources, transactions, or time-consuming non-blocking entities.
Thread pool reuses blocking threads based on the value specified for this property.

For workloads with large amounts of blocking threads, configure a blocking pool with a larger pool size.

|`EXPIRATION_SCHEDULED_EXECUTOR`|`1` / `0`| Based on the property's value, a reaper schedules checks on expired cache entries that exist in memory.
If your workload includes a large amount of expired cache entries that span multiple caches, consider setting a higher value for this property. 
Be mindful that setting a higher value does not increase the rate at which threads process expired cache entries. 
The default setting of `1` thread count indicates that one thread must handle all expired caches sequentially.
Increasing the thread count value means that more threads can handle caches in parallel order.

|`NON_BLOCKING_EXECUTOR` | `ProcessorInfo.availableProcessors() * 2` / `1000`| Property defines how a thread pool handles server operations and embedded cache operations. 
The `NON_BLOCKING_EXECUTOR` dispatches client requests on the server. 
Configuring this property is discouraged, because the default setting scales thread workload according to the size of your server installation, which ensures lower latency for thread operations.
|===

[IMPORTANT]
====
Applying a value greater than `2 * numCores` for the `NON_BLOCKING_EXECUTOR` property might lead to the creation of more threads, which can increase your server's memory footprint.  
====

[role="_additional-resources"]
.Additional resources
link:https://docs.jboss.org/infinispan/{schemaversion}/configdocs/infinispan-config-{schemaversion}.html[urn:infinispan:config:14.0]

[source,xml,options="nowrap", subs=attributes+]
.Thread pool configuration examples
----
include::xml/thread_cache_examples.xml[]
----


== Number of threads for Hot Rod connectors

The Hot Rod connector for {brandname} server uses worker threads that are
activated by clients requests. It is important to match the number of worker
threads to the number of concurrent client requests:

[source,xml,options="nowrap",subs=attributes+]
.Hot Rod Server worker thread pool size
----
include::xml/hotrod_worker_threads.xml[]
----

== SSL provider

{brandname} server will automatically use the native implementation of the OpenSSL libraries on supported platforms to
achieve much higher performance than what is possible with the JDK implementation of SSL.
OpenSSL is loaded dynamically, and its location can be specified by the `org.wildfly.openssl.path` system property.
If this property is not present, the standard system library search path will be used instead.
Because the library is loaded dynamically, it should be possible to use different versions of OpenSSL without the need to recompile.

== Cache store performance

In order to achieve the best performance, please follow the recommendations below when using cache stores:

* Use async mode (write-behind) if possible
* Prevent cache misses by preloading data
* For JDBC Cache Store:
** Use indexes on `id` column to prevent table scans
** Use PRIMARY_KEY on `id` column
** Configure batch-size, fetch-size, etc

== Hints for program developers

There are also several hints for developers which can be easily applied to the client application and will boost up the performance.

[discrete]
=== Ignore return values

When you're not interested in returning value of the `#put(k, v)` or `#remove(k)` method, use `Flag.IGNORE_RETURN_VALUES` flag as shown below:

.Using Flag.IGNORE_RETURN_VALUES
[source,java]
----
include::code_examples/GetAdvancedCacheWithFlagsIgnoreReturnValues.java[]
----

It is also possible to set this flag using ConfigurationBuilder

.Using ConfigurationBuilder settings
[source,java]
----
include::code_examples/ConfigurationBuilderUnreliableReturnValues.java[]
----

[discrete]
=== Use simple cache for local caches

When you don't need the full feature set of caches, you can set local cache to "simple" mode and achieve non-trivial speedup while still using {brandname} API.

This is an example comparison of the difference, randomly reading/writing into cache with 2048 entries as executed on 2x8-core Intel(R) Xeon(R) CPU E5-2640 v3 @ 2.60GHz:

.Number of operations per second (± std. dev.)
|===
| Cache type   | single-threaded cache.get(...) | single-threaded cache.put(...) | 32 threads cache.get(...) | 32 threads cache.put(...)

| Local cache  | 14,321,510 ± 260,807 |  1,141,168 ±  6,079 |   236,644,227 ± 2,657,918 |  2,287,708 ±   100,236
| Simple cache | 38,144,468 ± 575,420 | 11,706,053 ± 92,515 |   836,510,727 ± 3,176,794 | 47,971,836 ± 1,125,298
| CHM          | 60,592,770 ± 924,368 | 23,533,141 ± 98,632 | 1,369,521,754 ± 4,919,753 | 75,839,121 ± 3,319,835
|===

The CHM shows comparison for ConcurrentHashMap from JSR-166 with pluggable equality/hashCode function, which is used as the underlying storage in {brandname}.

Even though we use http://openjdk.java.net/projects/code-tools/jmh/[JMH] to prevent some common pitfalls of microbenchmarking, consider these results only approximate. Your mileage may vary.
